# Default values for druid.
# This is a YAML-formatted file.
# Declare variables to be passed into your templates.

replicaCount: 1

monitoring:
  enabled: false 
  serviceMonitor:
    enabled: false
    additionalLabels: {}
    namespace: ""
    namespaceSelector: {}
    scrapeInterval: 10s
    # honorLabels: true

repository: &rep dene14/druid
tag: &tag 0.16.1-3
pullPolicy: &pull IfNotPresent

broker:
  druid:
    JAVA_OPTS: "-javaagent:/opt/druid/lib/jmx_prometheus_javaagent-0.12.0.jar=1238:/etc/config.yaml -server -Xms8g -Xmx8g -XX:MaxDirectMemorySize=6192m -XX:+UseG1GC -XX:+ExitOnOutOfMemoryError -Duser.timezone=UTC -Dfile.encoding=UTF-8 -Djava.io.tmpdir=var/tmp -Djava.util.logging.manager=org.apache.logging.log4j.jul.LogManager -Dcom.sun.management.jmxremote.port=1235 -Dcom.sun.management.jmxremote.authenticate=false -Dcom.sun.management.jmxremote.ssl=false"
    service: druid/broker
    port: 8082
    broker:
      http:
        numConnections: 50
        maxQueuedBytes: "10000000"
      cache:
        useCache: false
        populateCache: false
    server:
      http:
        numThreads: 60
    cache:
      type: caffeine
      sizeInBytes: "536870912"
    # Processing threads and buffers
    processing:
      buffer:
        sizeBytes: "536870912"
      numThreads: 1
      numMergeBuffers: 6
    lookup:
      lookupTier: __default
  resources:
    limits:
      cpu: 2
      memory: 9Gi
    requests:
      cpu: 0.5
      memory: 8Gi
  image:
    repository: *rep
    tag: *tag
    pullPolicy: *pull

middlemanager:
  druid:
    JAVA_OPTS: "-javaagent:/opt/druid/lib/jmx_prometheus_javaagent-0.12.0.jar=1238:/etc/config.yaml -server -Xms64m -Xmx64m -Duser.timezone=UTC -Dfile.encoding=UTF-8 -Djava.io.tmpdir=var/tmp -Djava.util.logging.manager=org.apache.logging.log4j.jul.LogManager -Dcom.sun.management.jmxremote.port=1234 -Dcom.sun.management.jmxremote.authenticate=false -Dcom.sun.management.jmxremote.ssl=false"
    service: druid/middleManager
    port: 8091
    worker:
      capacity: 2
    server:
      http:
        numThreads: 25
    indexer:
      runner:
        javaOpts: "-server -Xmx3g -Duser.timezone=UTC -Dfile.encoding=UTF-8 -Djava.util.logging.manager=org.apache.logging.log4j.jul.LogManager"
      task:
        baseTaskDir: var/druid/task
        hadoopWorkingPath: var/druid/hadoop-tmp
        defaultHadoopCoordinates:
          - "org.apache.hadoop:hadoop-client:2.7.3"
      fork:
        property:
          druid:
            processing:
              numThreads: 2
              buffer:
                sizeBytes: "536870912"
    lookup:
      lookupTier: __default
  resources:
    # Peons use more memory than defined in JVM settings
    # TODO: Have to revisit and figure it out.
    # Could be a problem with garbage collector or DirectMemory
    limits:
      cpu: 2
      memory: 10Gi
    requests:
      cpu: 1
      memory: 5Gi
  persistence:
    enabled: false
    # storageClassName: default
    # accessModes:
    #   - ReadWriteOnce
    # size: 10Gi
    # annotations: {}
  image:
    repository: *rep
    tag: *tag
    pullPolicy: *pull

overlord:
  druid:
    JAVA_OPTS: "-javaagent:/opt/druid/lib/jmx_prometheus_javaagent-0.12.0.jar=1238:/etc/config.yaml -server -Xms3g -Xmx3g -XX:+UseG1GC -XX:+ExitOnOutOfMemoryError -Duser.timezone=UTC -Dfile.encoding=UTF-8 -Djava.io.tmpdir=/tmp -Djava.util.logging.manager=org.apache.logging.log4j.jul.LogManager -Dcom.sun.management.jmxremote.port=1234 -Dcom.sun.management.jmxremote.authenticate=false -Dcom.sun.management.jmxremote.ssl=false"
    service: druid/overlord
    port: 8090
    indexer:
      queue:
        startDelay: PT30S
      runner:
        type: remote
      storage:
        type: metadata
    lookup:
      lookupTier: __default
  resources:
    limits:
      cpu: 1
      memory: 4Gi
    requests:
      cpu: 0.5
      memory: 3Gi
  image:
    repository: *rep
    tag: *tag
    pullPolicy: *pull

coordinator:
  druid:
    JAVA_OPTS: "-javaagent:/opt/druid/lib/jmx_prometheus_javaagent-0.12.0.jar=1238:/etc/config.yaml -server -Xms1g -Xmx1g -XX:+UseG1GC -XX:+ExitOnOutOfMemoryError -Duser.timezone=UTC -Dfile.encoding=UTF-8 -Djava.io.tmpdir=var/tmp -Djava.util.logging.manager=org.apache.logging.log4j.jul.LogManager -Dderby.stream.error.file=var/druid/derby.log -Dcom.sun.management.jmxremote.port=1234 -Dcom.sun.management.jmxremote.authenticate=false -Dcom.sun.management.jmxremote.ssl=false"
    service: druid/coordinator
    port: 8081
    coordinator:
      startDelay: PT300S
      period: PT60S
      loadqueuepeon:
        type: curator
      merge:
        on: false
      kill:
        on: false
        maxSegments: 0
        durationToRetain: PT-1S
    serverview:
      type: batch
    lookup:
      lookupTier: __default
  image:
    repository: *rep
    tag: *tag
    pullPolicy: *pull

  resources:
    limits:
      cpu: 2
      memory: 2Gi
    requests:
      cpu: 0.5
      memory: 1Gi

historical:
  druid:
    JAVA_OPTS: "-javaagent:/opt/druid/lib/jmx_prometheus_javaagent-0.12.0.jar=1238:/etc/config.yaml -server -Xms16g -Xmx16g -XX:MaxDirectMemorySize=8192m -XX:+UseG1GC -XX:+ExitOnOutOfMemoryError -Duser.timezone=UTC -Dfile.encoding=UTF-8 -Djava.io.tmpdir=/tmp -Djava.util.logging.manager=org.apache.logging.log4j.jul.LogManager -Dcom.sun.management.jmxremote.port=1234 -Dcom.sun.management.jmxremote.authenticate=false -Dcom.sun.management.jmxremote.ssl=false"
    service: druid/historical
    port: 8083
    server:
      http:
        numThreads: 60
      maxSize: "130000000000"
    # TODO: think about dynamic volume allocation to reflect
    # configuration defined in segmentCache section
    segmentCache:
      locations:
        - path: "/var/druid/segment-cache"
          maxSize: "1300000000000"
          # This setting doesn't work for some reason
          # freeSpacePercent: 5.0
    historical:
      cache:
        useCache: false
        populateCache: false
    cache:
      type: caffeine
      sizeInBytes: "536870912"
    processing:
      numMergeBuffers: 2
      numThreads: 7
      buffer:
        sizeBytes: "536870912"
    lookup:
      lookupTier: __default
  resources:
    limits:
      cpu: 2
      memory: 9Gi
    requests:
      cpu: 1
      memory: 8Gi
  persistence:
    enabled: false
    # storageClassName: default
    # accessModes:
    #   - ReadWriteOnce
    # size: 10Gi
    # annotations: {}
  image:
    repository: *rep
    tag: *tag
    pullPolicy: *pull

router:
  druid:
    JAVA_OPTS: "-javaagent:/opt/druid/lib/jmx_prometheus_javaagent-0.12.0.jar=1238:/etc/config.yaml -server -Xms1g -Xmx1g -XX:+UseG1GC -XX:MaxDirectMemorySize=128m -XX:+ExitOnOutOfMemoryError -Duser.timezone=UTC -Dfile.encoding=UTF-8 -Djava.io.tmpdir=var/tmp -Djava.util.logging.manager=org.apache.logging.log4j.jul.LogManager -Dcom.sun.management.jmxremote.port=1234 -Dcom.sun.management.jmxremote.authenticate=false -Dcom.sun.management.jmxremote.ssl=false"
  image:
    repository: *rep
    tag: *tag
    pullPolicy: *pull

indexer:
  druid:
    JAVA_OPTS: "-javaagent:/opt/druid/lib/jmx_prometheus_javaagent-0.12.0.jar=1238:/etc/config.yaml -server -Xms3g -Xmx3g -Duser.timezone=UTC -Dcom.sun.management.jmxremote.port=1234 -Dcom.sun.management.jmxremote.authenticate=false -Dcom.sun.management.jmxremote.ssl=false"
  image:
    repository: *rep
    tag: *tag
    pullPolicy: *pull

global:
  #jmx_exporter:
    #image:
      #repository: sscaling/jmx-prometheus-exporter
      #tag: "latest"
    #JMXPORT: 1234
    #startDelaySeconds: 30

  druid:
    extensions:
      loadList:
      - "druid-kafka-eight"
      - "druid-s3-extensions"
      - "druid-histogram"
      - "druid-datasketches"
      - "druid-lookups-cached-global"
      - "mysql-metadata-storage"
    startup:
      logging:
        logProperties: "true"
    # Zookeeper
    zk:
      service:
        host: zk.host.ip
      paths:
        base: /druid
    # Metadata storage
    metadata:
      storage:
        type: derby
        connector:
          connectURI: "jdbc:derby://metadata.store.ip:1527/var/druid/metadata.db;create=true"
          host: metadata.store.ip
          port: 1527
    # Deep storage
    storage:
      type: local
      storageDirectory: var/druid/segments
      # For S3 type
      bucket: your-bucket
      baseKey: druid/segments
    # AWS keys
    #s3:
    #  accessKey: AAA
    #  secretKey: AAA
    # Indexing service logs
    indexer:
      logs:
        type: file
        directory: var/druid/indexing-logs
        # For S3
        #s3Bucket: your-bucket
        #s3Prefix: druid/indexing-logs
    # Service discovery
    selectors:
      indexing:
        serviceName: druid/overlord
      coordinator:
        serviceName: druid/coordinator
    # Monitoring
    monitoring:
      monitors:
      - "io.druid.java.util.metrics.JvmMonitor"
    emitter:
      composing:
        emitters:
        - "logging"
      logging:
        logLevel: info
    # Storage type of double columns
    indexing:
      doubleStorage: double
    javascript:
      enabled: false
    sql:
      enable: false

  monitoring:
    enabled: false
    name: debug
    image:
      repository: prom/statsd-exporter
      tag: v0.9.0
      pullPolicy: IfNotPresent
